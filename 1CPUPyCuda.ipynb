{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "1CPUPyCuda.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyO5iO251nkEhVoyxHKlU9qQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ismirnov56/MatmultCUDA/blob/main/1CPUPyCuda.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oc5J5PQKSHlx"
      },
      "source": [
        "# Лаборататорная работа \n",
        "\n",
        "Умножение матриц на CPU и GPU."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pfki4bUuqVDB"
      },
      "source": [
        "Даны две матрицы A и B, размера N*N.\n",
        "N от 100 до 2000. Измерение времени выполнения будем считать усреднённо по 10 попыткам."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P9q5JgIdSTBO"
      },
      "source": [
        "# 1. CPU \n",
        "\n",
        "## 1.1 столбец на строку \n",
        "В силу хорошей оптимизации библиотеки numpy и слишком медленного вычисления на CPU итеративно, мною было приянто решение умножать строку на столбец и производить суммирование."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y7cdzQKTlIki"
      },
      "source": [
        "import numpy as np\n",
        "from time import time\n",
        "\n",
        "def dot_(A,B):\n",
        "    n = A.shape[0]\n",
        "    C = np.zeros((n,n), dtype=np.float32)\n",
        "    for i in range(0,n):\n",
        "        for j in range(0,n):\n",
        "                C[i,j] += np.sum(A[i,:] * B[:,j]) \n",
        "    return C\n",
        "\n",
        "times_cpu_dot = []\n",
        "for n in range(100, 2001, 100):\n",
        "    A = np.random.randn(n, n).astype(np.float32)\n",
        "    B = np.random.randn(n, n).astype(np.float32)\n",
        "    t = 0.00\n",
        "    for i in range(10):\n",
        "        st = time()\n",
        "        C = dot_(A, B)\n",
        "        t += time() - st\n",
        "    times_cpu_dot.append(t/10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "thjJeshzxVHT",
        "outputId": "ce307c44-89be-4c0b-bb7d-890ce649ac02",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        }
      },
      "source": [
        "times_cpu_dot"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.057182598114013675,\n",
              " 0.24844889640808104,\n",
              " 0.569053339958191,\n",
              " 1.0408404350280762,\n",
              " 1.7208118200302125,\n",
              " 2.545329236984253,\n",
              " 3.6259246826171876,\n",
              " 4.9408704996109005,\n",
              " 6.345957517623901,\n",
              " 8.273769760131836,\n",
              " 9.732605457305908,\n",
              " 11.850897836685181,\n",
              " 14.464600157737731,\n",
              " 16.618010640144348,\n",
              " 19.606998634338378,\n",
              " 22.407856917381288,\n",
              " 25.54512333869934,\n",
              " 27.676632714271545,\n",
              " 30.627209424972534,\n",
              " 34.31349744796753]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sBW2U4Q6spBo"
      },
      "source": [
        "Небольшая проврерка работы"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qnv03-rusCOH",
        "outputId": "ebb945bd-361f-4b79-bc0b-3667901c387a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        }
      },
      "source": [
        "n = 5\n",
        "A = np.random.randn(n, n).astype(np.float32)\n",
        "B = np.random.randn(n, n).astype(np.float32)\n",
        "C1 = dot_(A, B)\n",
        "C2 = np.dot(A, B)\n",
        "print(n)\n",
        "print('-'*80)\n",
        "print(C1)\n",
        "print('-'*80)\n",
        "print(C2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5\n",
            "--------------------------------------------------------------------------------\n",
            "[[ 0.8727852   2.2140727  -3.6167493  -3.503257   -1.45942   ]\n",
            " [ 3.6286452  -4.345679   -5.476016   -0.834162   -2.739592  ]\n",
            " [ 4.943053   -1.7179002  -7.0439863  -0.868645   -2.7627974 ]\n",
            " [ 2.935496   -1.6183989  -3.2860298  -1.5042415  -1.7602518 ]\n",
            " [ 0.44490707 -1.8233428   0.14871609  3.9935079   0.5605775 ]]\n",
            "--------------------------------------------------------------------------------\n",
            "[[ 0.8727852   2.214073   -3.6167493  -3.503257   -1.4594201 ]\n",
            " [ 3.6286452  -4.345679   -5.476016   -0.834162   -2.739592  ]\n",
            " [ 4.943053   -1.7179002  -7.0439863  -0.8686449  -2.7627976 ]\n",
            " [ 2.935496   -1.6183989  -3.28603    -1.5042413  -1.7602518 ]\n",
            " [ 0.44490704 -1.8233432   0.14871606  3.9935076   0.5605775 ]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YsrEWmkKxhGX"
      },
      "source": [
        "## 1.2 Numpy dot"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qyu2uCR5xcyZ"
      },
      "source": [
        "times_cpu_npdot = []\n",
        "for n in range(100, 2001, 100):\n",
        "    A = np.random.randn(n, n).astype(np.float32)\n",
        "    B = np.random.randn(n, n).astype(np.float32)\n",
        "    t = 0.00\n",
        "    for i in range(10):\n",
        "        st = time()\n",
        "        C = np.dot(A, B)\n",
        "        t += time() - st\n",
        "    times_cpu_npdot.append(t/10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CE-OmD4kx1di",
        "outputId": "de045552-1502-47fe-976a-1d512c09d42e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        }
      },
      "source": [
        "times_cpu_npdot"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.0002835988998413086,\n",
              " 0.0002912759780883789,\n",
              " 0.0008139133453369141,\n",
              " 0.0017032384872436523,\n",
              " 0.0032474517822265623,\n",
              " 0.0054214239120483395,\n",
              " 0.008664226531982422,\n",
              " 0.013333439826965332,\n",
              " 0.01944878101348877,\n",
              " 0.027039146423339842,\n",
              " 0.03776769638061524,\n",
              " 0.048171067237854005,\n",
              " 0.06257970333099365,\n",
              " 0.0789381980895996,\n",
              " 0.10217525959014892,\n",
              " 0.10167536735534669,\n",
              " 0.12573959827423095,\n",
              " 0.14981493949890137,\n",
              " 0.18576388359069823,\n",
              " 0.21355531215667725]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w1M6HrjXq2nu"
      },
      "source": [
        "# 2. CUDA"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iR8f3qswrWcY"
      },
      "source": [
        "Определим размерность блоков, пусть он будет равен для всех задач 32.\n",
        "\n",
        "Размерность GRID будем вычислять как MATRIX_SIZE / BLOC_SIZE, если отстаток от деления не равен 0, то будем плюсовать 1. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g68ALvKup8lI"
      },
      "source": [
        "## 2.1 PyCUDA\n",
        "\n",
        "Установим PyCuda"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NEX20YxpRnGH"
      },
      "source": [
        "!pip install pycuda"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PdwCsxOFS_oG",
        "outputId": "39449856-659f-4c31-d2f3-0d057faaa3b2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "import pycuda.autoinit\n",
        "from pycuda.tools import make_default_context\n",
        "make_default_context().get_device().name()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Tesla T4'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tlfObNF2qCh0"
      },
      "source": [
        "### 2.1.1 Решаем задачу в 'лоб'.\n",
        "Матрицы расположены в глобальной памяти.\n",
        "По одной нити на каждый элемент произведения."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GYkpUEtw9WON"
      },
      "source": [
        "Проверка работы алгоритма в лоб."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kq4485yq4baH",
        "outputId": "80ac98f6-6c6b-4f82-8db6-513d01bf461c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from pycuda import driver, compiler, gpuarray, tools\n",
        "import pycuda.autoinit\n",
        "\n",
        "BLOCK_SIZE = 32\n",
        "\n",
        "kernel_code_template = \"\"\" \n",
        "__global__ void MatrixMulKernel(float *a, float *b, float *c) \n",
        "{\n",
        "    int tx = threadIdx.x;\n",
        "    int ty = threadIdx.y;\n",
        "\n",
        "    int bx = blockIdx.x;\n",
        "    int by = blockIdx.y;\n",
        "\n",
        "    int row = by*blockDim.y + ty;\n",
        "    int col = bx*blockDim.x + tx;\n",
        "\n",
        "    if(row < %(MATRIX_SIZE)s && col < %(MATRIX_SIZE)s){\n",
        "        float val = 0.0;\n",
        "        for(int i=0; i<%(MATRIX_SIZE)s; ++i){\n",
        "            val += a[row*%(MATRIX_SIZE)s + i]*b[%(MATRIX_SIZE)s*i + col];\n",
        "        }\n",
        "        c[row*%(MATRIX_SIZE)s + col] = val;\n",
        "    }\n",
        "}\"\"\"\n",
        "\n",
        "MATRIX_SIZE = 10\n",
        "if MATRIX_SIZE % BLOCK_SIZE != 0:\n",
        "    GRID_SIZE = int(MATRIX_SIZE / BLOCK_SIZE) + 1 \n",
        "else:\n",
        "    GRID_SIZE = int(MATRIX_SIZE / BLOCK_SIZE)\n",
        "a_cpu = np.random.randn(MATRIX_SIZE, MATRIX_SIZE).astype(np.float32)\n",
        "b_cpu = np.random.randn(MATRIX_SIZE, MATRIX_SIZE).astype(np.float32)\n",
        "c_cpu = np.dot(a_cpu, b_cpu)\n",
        "\n",
        "a_gpu = gpuarray.to_gpu(a_cpu)\n",
        "b_gpu = gpuarray.to_gpu(b_cpu)\n",
        "\n",
        "c_gpu = gpuarray.empty((MATRIX_SIZE, MATRIX_SIZE), np.float32)\n",
        "kernel_code = kernel_code_template % { \n",
        "            'MATRIX_SIZE': MATRIX_SIZE}\n",
        "\n",
        "mod = compiler.SourceModule(kernel_code)\n",
        "\n",
        "matrixmul = mod.get_function(\"MatrixMulKernel\")\n",
        "\n",
        "matrixmul(\n",
        "      # inputs\n",
        "      a_gpu, b_gpu,\n",
        "      # output\n",
        "      c_gpu,\n",
        "      # grid of multiple blocks\n",
        "      grid = (GRID_SIZE, GRID_SIZE, 1),\n",
        "      # block of multiple threads\n",
        "      block = (BLOCK_SIZE, BLOCK_SIZE, 1),\n",
        ")\n",
        "new_c = c_gpu.get()\n",
        "print(MATRIX_SIZE)\n",
        "print('-'*80)\n",
        "print(new_c)\n",
        "print('-'*80)\n",
        "print(c_cpu)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10\n",
            "--------------------------------------------------------------------------------\n",
            "[[ 9.5178723e-02 -3.0408013e+00 -1.6342096e+00  3.8664782e+00\n",
            "  -2.4041240e+00  7.6266899e+00  7.6707534e-02 -2.7174252e-01\n",
            "  -4.1617970e+00 -4.3061137e+00]\n",
            " [ 2.4408448e+00  1.4186980e+00  2.2919505e+00 -1.3994753e+00\n",
            "  -2.3594863e+00  1.0295769e+00  2.0540612e+00 -5.0135803e-01\n",
            "   1.1066291e-01 -1.7442271e+00]\n",
            " [ 9.1642213e-01  4.1572517e-01  4.0755997e+00 -9.6282262e-01\n",
            "   1.5606560e+00  6.1136141e+00 -1.0149521e-01 -4.9460311e+00\n",
            "  -4.4111109e+00  2.7175677e+00]\n",
            " [ 4.6664634e-01  2.2396359e+00 -7.5080919e+00 -1.3747448e+00\n",
            "  -1.5701208e-01  5.0243485e-01 -5.3436546e+00 -1.0699104e+00\n",
            "   3.5423408e+00  8.8724762e-01]\n",
            " [ 1.2252010e+00  3.7863757e-03 -3.2837532e+00  2.9553261e+00\n",
            "  -6.6604924e+00 -6.3805832e-03 -2.9731662e+00 -9.4810218e-01\n",
            "  -4.2168722e-01  2.9286921e+00]\n",
            " [-1.8680295e+00 -2.0434134e+00 -4.2758889e+00  1.8256086e+00\n",
            "   9.6860927e-01  1.8808706e+00 -4.0365648e+00  9.1430330e-01\n",
            "   2.0420721e+00 -3.1767306e+00]\n",
            " [-2.3165772e+00 -1.0665234e+00  2.0013864e+00 -3.0524415e-01\n",
            "   6.5694362e-01 -1.7401341e+00  9.9445152e-01 -2.7212906e+00\n",
            "   6.7320900e+00  2.2697625e+00]\n",
            " [-1.4133013e+00 -1.0950596e+00  1.7864259e+00 -8.9549333e-01\n",
            "   1.2216448e+00  2.6654341e+00  2.2565002e+00 -2.5350163e+00\n",
            "   6.3206873e+00 -2.3412993e+00]\n",
            " [ 7.0231050e-01 -5.5044383e-01  3.8972728e+00 -1.5294347e+00\n",
            "   8.7566662e+00  1.5517186e+00  4.8243866e+00 -3.1697321e+00\n",
            "   1.3142151e+01  4.7895236e+00]\n",
            " [-1.6612947e+00 -1.1883045e+00  1.3837814e-01  2.4391149e-01\n",
            "   2.3453660e+00  1.2014670e+00  2.6974785e+00 -4.6351275e-01\n",
            "   2.5612071e+00 -1.3545331e+00]]\n",
            "--------------------------------------------------------------------------------\n",
            "[[ 9.5178723e-02 -3.0408013e+00 -1.6342096e+00  3.8664782e+00\n",
            "  -2.4041240e+00  7.6266899e+00  7.6707534e-02 -2.7174252e-01\n",
            "  -4.1617970e+00 -4.3061137e+00]\n",
            " [ 2.4408448e+00  1.4186980e+00  2.2919505e+00 -1.3994753e+00\n",
            "  -2.3594863e+00  1.0295769e+00  2.0540612e+00 -5.0135803e-01\n",
            "   1.1066291e-01 -1.7442271e+00]\n",
            " [ 9.1642213e-01  4.1572517e-01  4.0755997e+00 -9.6282262e-01\n",
            "   1.5606560e+00  6.1136141e+00 -1.0149521e-01 -4.9460311e+00\n",
            "  -4.4111109e+00  2.7175677e+00]\n",
            " [ 4.6664634e-01  2.2396359e+00 -7.5080919e+00 -1.3747448e+00\n",
            "  -1.5701208e-01  5.0243485e-01 -5.3436546e+00 -1.0699104e+00\n",
            "   3.5423408e+00  8.8724762e-01]\n",
            " [ 1.2252010e+00  3.7863757e-03 -3.2837532e+00  2.9553261e+00\n",
            "  -6.6604924e+00 -6.3805832e-03 -2.9731662e+00 -9.4810218e-01\n",
            "  -4.2168722e-01  2.9286921e+00]\n",
            " [-1.8680295e+00 -2.0434134e+00 -4.2758889e+00  1.8256086e+00\n",
            "   9.6860927e-01  1.8808706e+00 -4.0365648e+00  9.1430330e-01\n",
            "   2.0420721e+00 -3.1767306e+00]\n",
            " [-2.3165772e+00 -1.0665234e+00  2.0013864e+00 -3.0524415e-01\n",
            "   6.5694362e-01 -1.7401341e+00  9.9445152e-01 -2.7212906e+00\n",
            "   6.7320900e+00  2.2697625e+00]\n",
            " [-1.4133013e+00 -1.0950596e+00  1.7864259e+00 -8.9549333e-01\n",
            "   1.2216448e+00  2.6654341e+00  2.2565002e+00 -2.5350163e+00\n",
            "   6.3206873e+00 -2.3412993e+00]\n",
            " [ 7.0231050e-01 -5.5044383e-01  3.8972728e+00 -1.5294347e+00\n",
            "   8.7566662e+00  1.5517186e+00  4.8243866e+00 -3.1697321e+00\n",
            "   1.3142151e+01  4.7895236e+00]\n",
            " [-1.6612947e+00 -1.1883045e+00  1.3837814e-01  2.4391149e-01\n",
            "   2.3453660e+00  1.2014670e+00  2.6974785e+00 -4.6351275e-01\n",
            "   2.5612071e+00 -1.3545331e+00]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9CbC-cZP9x2F"
      },
      "source": [
        "Расчёт времени."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d5OF5QN19mo7"
      },
      "source": [
        "times_pycuda_glob = []\n",
        "for n in range(100, 2001, 100):\n",
        "    MATRIX_SIZE = n\n",
        "    if MATRIX_SIZE % BLOCK_SIZE != 0:\n",
        "        GRID_SIZE = int(MATRIX_SIZE / BLOCK_SIZE) + 1 \n",
        "    else:\n",
        "        GRID_SIZE = int(MATRIX_SIZE / BLOCK_SIZE)\n",
        "    a_cpu = np.random.randn(MATRIX_SIZE, MATRIX_SIZE).astype(np.float32)\n",
        "    b_cpu = np.random.randn(MATRIX_SIZE, MATRIX_SIZE).astype(np.float32)\n",
        "    \n",
        "    t = 0.00\n",
        "    for i in range(10):\n",
        "        st = time()\n",
        "        a_gpu = gpuarray.to_gpu(a_cpu)\n",
        "        b_gpu = gpuarray.to_gpu(b_cpu)\n",
        "\n",
        "        c_gpu = gpuarray.empty((MATRIX_SIZE, MATRIX_SIZE), np.float32)\n",
        "        kernel_code = kernel_code_template % { \n",
        "            'MATRIX_SIZE': MATRIX_SIZE}\n",
        "\n",
        "        mod = compiler.SourceModule(kernel_code)\n",
        "\n",
        "        matrixmul = mod.get_function(\"MatrixMulKernel\")\n",
        "\n",
        "        matrixmul(\n",
        "            # inputs\n",
        "            a_gpu, b_gpu,\n",
        "            # output\n",
        "            c_gpu,\n",
        "            # grid of multiple blocks\n",
        "            grid = (GRID_SIZE, GRID_SIZE, 1),\n",
        "            # block of multiple threads\n",
        "            block = (BLOCK_SIZE, BLOCK_SIZE, 1),\n",
        "        )\n",
        "        new_c = c_gpu.get()\n",
        "        t += time() - st\n",
        "    times_pycuda_glob.append(t/10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9AHJDgmM94Tb",
        "outputId": "1bb97174-a6ed-4f38-b1c0-a33c0479ab31",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        }
      },
      "source": [
        "times_pycuda_glob"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.0276444673538208,\n",
              " 0.02657451629638672,\n",
              " 0.028185415267944335,\n",
              " 0.027504897117614745,\n",
              " 0.02899048328399658,\n",
              " 0.030380797386169434,\n",
              " 0.030751371383666994,\n",
              " 0.032529616355896,\n",
              " 0.035014891624450685,\n",
              " 0.036918258666992186,\n",
              " 0.041953206062316895,\n",
              " 0.04360098838806152,\n",
              " 0.04504399299621582,\n",
              " 0.04587640762329102,\n",
              " 0.04921045303344727,\n",
              " 0.04610986709594726,\n",
              " 0.049653244018554685,\n",
              " 0.055193972587585446,\n",
              " 0.05788938999176026,\n",
              " 0.06183755397796631]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xDCLJhif-Dui"
      },
      "source": [
        "На каждый элемент произведения матриц\n",
        "2*N арифметических операций\n",
        "2*N обращений к глобальной памяти\n",
        "Таким образом можно сделать вывод, что быстродействие алгоритма завст от доступа к памяти, что является более долгим."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tlP11uSx-jbg"
      },
      "source": [
        "## 2.1.2 Решение с использованием разделяемой памяти\n",
        "\n",
        "При вычислении C постоянно\n",
        "используются одни и те же\n",
        "элементы из A и B\n",
        "\n",
        "Эти элементы образуют полосы, Размер одной полосы N на BLOCK_SIZE, поэтому даже одна полоса в разделяемую память не помещается. Для этого будет производится, делени на блоки BLOCK_SIZE на BLOCK_SIZE. Хранить в shared-памяти необходимо только две подматрицы BLOCK_SIZE на BLOCK_SIZE.\n",
        "\n",
        "Загрузить необходимые данные (часть) в\n",
        "разделяемую память (из глобальной)\n",
        "__syncthreads();\n",
        "Выполнить вычисления над обработанными данными\n",
        "__syncthreads();\n",
        "Записать результат в глобальную память\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vN9s6jW5SkCd"
      },
      "source": [
        "Также добавим проверку, на то, что матрица не кратная. Если это так, то заполняем shared блоки 0"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JJsCk7JuK_qz",
        "outputId": "8449a585-eba6-43ac-8c16-f8c1a6ed4ca1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 403
        }
      },
      "source": [
        "from pycuda import driver, compiler, gpuarray, tools\n",
        "import pycuda.autoinit\n",
        "\n",
        "BLOCK_SIZE = 32\n",
        "\n",
        "kernel_code_template_shared = \"\"\" \n",
        "__global__ void MatrixMulKernelShared(float *a, float *b, float *c) \n",
        "{\n",
        "    __shared__ float sA[%(BLOCK_SIZE)s][%(BLOCK_SIZE)s]; \n",
        "    __shared__ float sB[%(BLOCK_SIZE)s][%(BLOCK_SIZE)s];\n",
        "\n",
        "    int row = blockDim.y*blockIdx.y + threadIdx.y;\n",
        "    int col = blockDim.x*blockIdx.x + threadIdx.x;\n",
        "    float value = 0.0;\n",
        "\n",
        "    sA[threadIdx.y][threadIdx.x] = 0.0;\n",
        "    sB[threadIdx.y][threadIdx.x] = 0.0;\n",
        "\n",
        "    for(int i = 0; i < (((%(MATRIX_SIZE)s - 1)/%(BLOCK_SIZE)s) + 1); i++)\n",
        "    {\n",
        "        if((row < %(MATRIX_SIZE)s) && (threadIdx.x + (i* %(BLOCK_SIZE)s)) < %(MATRIX_SIZE)s)\n",
        "            sA[threadIdx.y][threadIdx.x] = a[(row*%(MATRIX_SIZE)s) + threadIdx.x + (i* %(BLOCK_SIZE)s)];\n",
        "        if(col < %(MATRIX_SIZE)s && (threadIdx.y + i * %(BLOCK_SIZE)s) < %(MATRIX_SIZE)s)\n",
        "            sB[threadIdx.y][threadIdx.x] = b[(threadIdx.y + i * %(BLOCK_SIZE)s)*%(MATRIX_SIZE)s + col];\n",
        "        __syncthreads();\n",
        "\n",
        "        for(int j = 0; j <  %(BLOCK_SIZE)s; ++j)\n",
        "            value += sA[threadIdx.y][j] * sB[j][threadIdx.x];\n",
        "    }\n",
        "    if(row < %(MATRIX_SIZE)s && col < %(MATRIX_SIZE)s)\n",
        "        c[row*%(MATRIX_SIZE)s + col] = value;\n",
        "\n",
        "}\"\"\"\n",
        "\n",
        "MATRIX_SIZE = 5\n",
        "if MATRIX_SIZE % BLOCK_SIZE != 0:\n",
        "    GRID_SIZE = int(MATRIX_SIZE / BLOCK_SIZE) + 1 \n",
        "else:\n",
        "    GRID_SIZE = int(MATRIX_SIZE / BLOCK_SIZE)\n",
        "a_cpu = np.random.randn(MATRIX_SIZE, MATRIX_SIZE).astype(np.float32)\n",
        "b_cpu = np.random.randn(MATRIX_SIZE, MATRIX_SIZE).astype(np.float32)\n",
        "c_cpu = np.dot(a_cpu, b_cpu)\n",
        "\n",
        "a_gpu = gpuarray.to_gpu(a_cpu)\n",
        "b_gpu = gpuarray.to_gpu(b_cpu)\n",
        "\n",
        "c_gpu = gpuarray.empty((MATRIX_SIZE, MATRIX_SIZE), np.float32)\n",
        "\n",
        "kernel_code_shared = kernel_code_template_shared % {\n",
        "            'BLOCK_SIZE': BLOCK_SIZE,\n",
        "            'MATRIX_SIZE': MATRIX_SIZE}\n",
        "\n",
        "mod = compiler.SourceModule(kernel_code_shared)\n",
        "\n",
        "matrixmul = mod.get_function(\"MatrixMulKernelShared\")\n",
        "\n",
        "matrixmul(\n",
        "      # inputs\n",
        "      a_gpu, b_gpu,\n",
        "      # output\n",
        "      c_gpu,\n",
        "      # grid of multiple blocks\n",
        "      grid = (GRID_SIZE, GRID_SIZE, 1),\n",
        "      # block of multiple threads\n",
        "      block = (BLOCK_SIZE, BLOCK_SIZE, 1),\n",
        ")\n",
        "new_c = c_gpu.get()\n",
        "print(MATRIX_SIZE)\n",
        "print('-'*80)\n",
        "print(new_c)\n",
        "print('-'*80)\n",
        "print(c_cpu)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5\n",
            "--------------------------------------------------------------------------------\n",
            "[[ 1.1870606e-03  6.7894685e-01 -1.4249148e+00  4.3021947e-01\n",
            "  -6.6550052e-01]\n",
            " [ 1.3419559e+00 -1.9053680e+00  3.1952651e+00 -2.0126512e+00\n",
            "   7.8941145e+00]\n",
            " [ 5.3654552e-01 -6.1682677e-01  3.3089730e-01 -7.0139545e-01\n",
            "  -3.1006208e-01]\n",
            " [-1.1755749e+00 -1.3618978e+00 -9.6797323e-01 -2.2385228e+00\n",
            "   1.4731802e+00]\n",
            " [-1.6252077e-01  7.9803962e-01  5.2018631e-01  6.6955522e-02\n",
            "   5.7431364e-01]]\n",
            "--------------------------------------------------------------------------------\n",
            "[[ 1.1870606e-03  6.7894685e-01 -1.4249148e+00  4.3021947e-01\n",
            "  -6.6550052e-01]\n",
            " [ 1.3419559e+00 -1.9053680e+00  3.1952651e+00 -2.0126512e+00\n",
            "   7.8941145e+00]\n",
            " [ 5.3654552e-01 -6.1682677e-01  3.3089730e-01 -7.0139545e-01\n",
            "  -3.1006208e-01]\n",
            " [-1.1755749e+00 -1.3618978e+00 -9.6797323e-01 -2.2385228e+00\n",
            "   1.4731802e+00]\n",
            " [-1.6252077e-01  7.9803962e-01  5.2018631e-01  6.6955522e-02\n",
            "   5.7431364e-01]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FRiqG6h3T9Q3"
      },
      "source": [
        "Алгоритм работает произведём измерение времени"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CSGqYwJtUDAD"
      },
      "source": [
        "times_pycuda_shared = []\n",
        "for n in range(100, 2001, 100):\n",
        "    MATRIX_SIZE = n\n",
        "    if MATRIX_SIZE % BLOCK_SIZE != 0:\n",
        "        GRID_SIZE = int(MATRIX_SIZE / BLOCK_SIZE) + 1 \n",
        "    else:\n",
        "        GRID_SIZE = int(MATRIX_SIZE / BLOCK_SIZE)\n",
        "    a_cpu = np.random.randn(MATRIX_SIZE, MATRIX_SIZE).astype(np.float32)\n",
        "    b_cpu = np.random.randn(MATRIX_SIZE, MATRIX_SIZE).astype(np.float32)\n",
        "    \n",
        "    t = 0.00\n",
        "    for i in range(10):\n",
        "        st = time()\n",
        "        a_gpu = gpuarray.to_gpu(a_cpu)\n",
        "        b_gpu = gpuarray.to_gpu(b_cpu)\n",
        "\n",
        "        c_gpu = gpuarray.empty((MATRIX_SIZE, MATRIX_SIZE), np.float32)\n",
        "        kernel_code_shared = kernel_code_template_shared % {\n",
        "            'BLOCK_SIZE': BLOCK_SIZE,\n",
        "            'MATRIX_SIZE': MATRIX_SIZE}\n",
        "\n",
        "        mod = compiler.SourceModule(kernel_code_shared)\n",
        "\n",
        "        matrixmul = mod.get_function(\"MatrixMulKernelShared\")\n",
        "\n",
        "        matrixmul(\n",
        "            # inputs\n",
        "            a_gpu, b_gpu,\n",
        "            # output\n",
        "            c_gpu,\n",
        "            # grid of multiple blocks\n",
        "            grid = (GRID_SIZE, GRID_SIZE, 1),\n",
        "            # block of multiple threads\n",
        "            block = (BLOCK_SIZE, BLOCK_SIZE, 1),\n",
        "        )\n",
        "        new_c = c_gpu.get()\n",
        "        t += time() - st\n",
        "    times_pycuda_shared.append(t/10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5TXdLyanUZcQ",
        "outputId": "b4c47095-9544-4ccb-ea52-e375b6a83476",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        }
      },
      "source": [
        "times_pycuda_shared"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.028669977188110353,\n",
              " 0.02777731418609619,\n",
              " 0.02806820869445801,\n",
              " 0.028605055809020997,\n",
              " 0.030236291885375976,\n",
              " 0.030353856086730958,\n",
              " 0.0315310001373291,\n",
              " 0.03389830589294433,\n",
              " 0.036460375785827635,\n",
              " 0.0373795747756958,\n",
              " 0.039292764663696286,\n",
              " 0.04307260513305664,\n",
              " 0.04505701065063476,\n",
              " 0.04582734107971191,\n",
              " 0.04802858829498291,\n",
              " 0.049235296249389646,\n",
              " 0.04838404655456543,\n",
              " 0.052605485916137694,\n",
              " 0.056986427307128905,\n",
              " 0.05988717079162598]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r1D3yTycZE3g"
      },
      "source": [
        "## 2.2 Numba\n",
        "\n",
        "Представлен во другом notebook, а резуьтаты сохраним с помощью pandas."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l38a2FvmjM1L"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "data = {\n",
        "    'N': [*range(100, 2001, 100)],\n",
        "    'cpu': times_cpu_dot,\n",
        "    'numpy': times_cpu_npdot,\n",
        "    'pycuda': times_pycuda_glob,\n",
        "    'pycuda with shared': times_pycuda_shared\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "93wZqi0SkrI5",
        "outputId": "1e199d23-6dbd-4838-a9f5-8141b66b2990",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yxmv5ryMk6BH"
      },
      "source": [
        "df.to_csv('drive/My Drive/data/pycuda.csv', index=False)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}